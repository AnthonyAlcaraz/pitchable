---
phase: 02-knowledge-base
plan: 03
type: execute
wave: 3
depends_on: ["02-01", "02-02"]
files_modified:
  - apps/api/src/knowledge-base/embedding/embedding.service.ts
  - apps/api/src/knowledge-base/embedding/vector-store.service.ts
  - apps/api/src/knowledge-base/document-processing.processor.ts
  - apps/api/src/knowledge-base/knowledge-base.controller.ts
  - apps/api/src/knowledge-base/knowledge-base.service.ts
  - apps/api/src/knowledge-base/dto/search-kb.dto.ts
  - apps/api/src/knowledge-base/knowledge-base.module.ts
autonomous: true

must_haves:
  truths:
    - "After document processing completes, chunks have embedding vectors stored in pgvector"
    - "Document status transitions from EMBEDDING to READY after vectors are stored"
    - "User can query their knowledge base and receive semantically relevant chunks"
    - "Search results include similarity score, document title, heading context"
    - "Embedding generation uses OpenAI text-embedding-3-small (1536 dimensions)"
    - "Vector similarity search uses cosine distance via pgvector <=> operator"
  artifacts:
    - path: "apps/api/src/knowledge-base/embedding/embedding.service.ts"
      provides: "OpenAI embedding generation with batching"
      exports: ["EmbeddingService"]
    - path: "apps/api/src/knowledge-base/embedding/vector-store.service.ts"
      provides: "pgvector raw SQL operations (insert, search, delete)"
      exports: ["VectorStoreService"]
    - path: "apps/api/src/knowledge-base/dto/search-kb.dto.ts"
      provides: "Search request DTO with query, limit, threshold"
      exports: ["SearchKbDto"]
  key_links:
    - from: "apps/api/src/knowledge-base/document-processing.processor.ts"
      to: "apps/api/src/knowledge-base/embedding/embedding.service.ts"
      via: "constructor injection, batchEmbed call"
      pattern: "embeddingService\\.batchEmbed"
    - from: "apps/api/src/knowledge-base/document-processing.processor.ts"
      to: "apps/api/src/knowledge-base/embedding/vector-store.service.ts"
      via: "constructor injection, updateChunkEmbeddings call"
      pattern: "vectorStore\\.updateChunkEmbeddings"
    - from: "apps/api/src/knowledge-base/knowledge-base.controller.ts"
      to: "apps/api/src/knowledge-base/knowledge-base.service.ts"
      via: "search endpoint delegates to service"
      pattern: "kbService\\.search"
    - from: "apps/api/src/knowledge-base/knowledge-base.service.ts"
      to: "apps/api/src/knowledge-base/embedding/embedding.service.ts"
      via: "embed query text before searching"
      pattern: "embeddingService\\.embed"
    - from: "apps/api/src/knowledge-base/embedding/vector-store.service.ts"
      to: "prisma.$queryRaw"
      via: "raw SQL with pgvector operators"
      pattern: "embedding.*<=>.*vector"
---

<objective>
Add embedding generation (OpenAI text-embedding-3-small) and pgvector storage/search to the KB pipeline. Integrate embeddings into the existing document-processing processor so chunks get vectors after being stored. Add a RAG retrieval endpoint (POST /knowledge-base/search) that embeds a query and returns the most similar chunks.

Purpose: This is the intelligence layer -- without embeddings and vector search, the KB is just a document store. With it, Phase 3's chat engine can retrieve relevant content for slide generation.

Output: Complete document processing pipeline (upload -> parse -> chunk -> embed -> store), working semantic search endpoint.
</objective>

<execution_context>
@C:\Users\33641\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\33641\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@C:\Users\33641\projects\slide-saas\.planning\PROJECT.md
@C:\Users\33641\projects\slide-saas\.planning\ROADMAP.md
@C:\Users\33641\projects\slide-saas\.planning\STATE.md
@C:\Users\33641\projects\slide-saas\.planning\phases\02-knowledge-base\02-RESEARCH.md
@C:\Users\33641\projects\slide-saas\.planning\phases\02-knowledge-base\02-01-SUMMARY.md
@C:\Users\33641\projects\slide-saas\.planning\phases\02-knowledge-base\02-02-SUMMARY.md

Key existing files to reference:
@C:\Users\33641\projects\slide-saas\apps\api\src\knowledge-base\document-processing.processor.ts
@C:\Users\33641\projects\slide-saas\apps\api\src\knowledge-base\knowledge-base.service.ts
@C:\Users\33641\projects\slide-saas\apps\api\src\knowledge-base\knowledge-base.controller.ts
@C:\Users\33641\projects\slide-saas\apps\api\src\knowledge-base\knowledge-base.module.ts
@C:\Users\33641\projects\slide-saas\apps\api\src\prisma\prisma.service.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Embedding service, vector store service, and search DTO</name>
  <files>
    apps/api/src/knowledge-base/embedding/embedding.service.ts
    apps/api/src/knowledge-base/embedding/vector-store.service.ts
    apps/api/src/knowledge-base/dto/search-kb.dto.ts
  </files>
  <action>
**Step 1: Create embedding service** (`apps/api/src/knowledge-base/embedding/embedding.service.ts`):
```typescript
import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';

@Injectable()
export class EmbeddingService {
  private readonly logger = new Logger(EmbeddingService.name);
  private readonly openai: OpenAI;
  private readonly model = 'text-embedding-3-small';

  constructor(config: ConfigService) {
    const apiKey = config.get<string>('OPENAI_API_KEY');
    if (!apiKey) {
      this.logger.warn('OPENAI_API_KEY not set -- embedding generation will fail at runtime');
    }
    this.openai = new OpenAI({ apiKey: apiKey || 'missing' });
  }

  async embed(text: string): Promise<number[]> {
    const response = await this.openai.embeddings.create({
      model: this.model,
      input: text,
    });
    return response.data[0].embedding; // 1536-dimensional vector
  }

  async batchEmbed(texts: string[]): Promise<number[][]> {
    if (texts.length === 0) return [];

    const results: number[][] = [];
    const BATCH_SIZE = 100; // OpenAI limit is 2048, we use 100 for safety

    for (let i = 0; i < texts.length; i += BATCH_SIZE) {
      const batch = texts.slice(i, i + BATCH_SIZE);
      this.logger.log(
        `Embedding batch ${Math.floor(i / BATCH_SIZE) + 1}/${Math.ceil(texts.length / BATCH_SIZE)}: ${batch.length} texts`,
      );

      const response = await this.openai.embeddings.create({
        model: this.model,
        input: batch,
      });

      // Response data maintains input order
      results.push(...response.data.map((d) => d.embedding));
    }

    return results;
  }
}
```

**Step 2: Create vector store service** (`apps/api/src/knowledge-base/embedding/vector-store.service.ts`):

This service uses `prisma.$executeRaw` and `prisma.$queryRaw` with the `pgvector` npm package for SQL-compatible vector conversion.

```typescript
import { Injectable, Logger } from '@nestjs/common';
import { PrismaService } from '../../prisma/prisma.service.js';
import pgvector from 'pgvector';

export interface SearchResult {
  id: string;
  content: string;
  heading: string | null;
  headingLevel: number;
  metadata: Record<string, unknown>;
  documentId: string;
  documentTitle: string;
  similarity: number;
}

@Injectable()
export class VectorStoreService {
  private readonly logger = new Logger(VectorStoreService.name);

  constructor(private readonly prisma: PrismaService) {}

  /**
   * Update chunk embeddings for a document.
   * Chunks must already exist in the DB (created by the parsing step).
   * This updates the embedding column for each chunk.
   */
  async updateChunkEmbeddings(
    documentId: string,
    chunkEmbeddings: { chunkId: string; embedding: number[] }[],
  ): Promise<void> {
    for (const { chunkId, embedding } of chunkEmbeddings) {
      const vectorSql = pgvector.toSql(embedding);
      await this.prisma.$executeRaw`
        UPDATE "DocumentChunk"
        SET "embedding" = ${vectorSql}::vector
        WHERE "id" = ${chunkId}::uuid
          AND "documentId" = ${documentId}::uuid
      `;
    }
    this.logger.log(
      `Updated ${chunkEmbeddings.length} embeddings for document ${documentId}`,
    );
  }

  /**
   * Semantic similarity search across a user's knowledge base.
   * Uses cosine distance via pgvector's <=> operator.
   */
  async searchSimilar(
    userId: string,
    queryEmbedding: number[],
    limit = 10,
    threshold = 0.3,
  ): Promise<SearchResult[]> {
    const vectorSql = pgvector.toSql(queryEmbedding);

    const results = await this.prisma.$queryRaw<SearchResult[]>`
      SELECT
        dc."id",
        dc."content",
        dc."heading",
        dc."headingLevel",
        dc."metadata",
        dc."documentId",
        d."title" as "documentTitle",
        (1 - (dc."embedding" <=> ${vectorSql}::vector)) as "similarity"
      FROM "DocumentChunk" dc
      JOIN "Document" d ON d."id" = dc."documentId"
      WHERE d."userId" = ${userId}::uuid
        AND d."status" = 'READY'
        AND dc."embedding" IS NOT NULL
        AND (1 - (dc."embedding" <=> ${vectorSql}::vector)) > ${threshold}
      ORDER BY dc."embedding" <=> ${vectorSql}::vector
      LIMIT ${limit}
    `;

    return results;
  }

  /**
   * Delete all chunk embeddings for a document (used when re-processing).
   */
  async deleteDocumentEmbeddings(documentId: string): Promise<void> {
    await this.prisma.$executeRaw`
      UPDATE "DocumentChunk"
      SET "embedding" = NULL
      WHERE "documentId" = ${documentId}::uuid
    `;
  }
}
```

NOTE on pgvector import: If `import pgvector from 'pgvector'` fails, try `import * as pgvector from 'pgvector'`. The pgvector npm package may use CommonJS exports.

**Step 3: Create search DTO** (`apps/api/src/knowledge-base/dto/search-kb.dto.ts`):
```typescript
import { ApiProperty, ApiPropertyOptional } from '@nestjs/swagger';
import { IsString, IsOptional, IsInt, IsNumber, Min, Max, MinLength } from 'class-validator';
import { Type } from 'class-transformer';

export class SearchKbDto {
  @ApiProperty({ description: 'Search query text', example: 'AI agent architecture' })
  @IsString()
  @MinLength(1)
  query: string;

  @ApiPropertyOptional({ description: 'Max results to return', default: 10 })
  @IsOptional()
  @Type(() => Number)
  @IsInt()
  @Min(1)
  @Max(50)
  limit?: number = 10;

  @ApiPropertyOptional({ description: 'Minimum similarity threshold (0-1)', default: 0.3 })
  @IsOptional()
  @Type(() => Number)
  @IsNumber()
  @Min(0)
  @Max(1)
  threshold?: number = 0.3;
}
```
  </action>
  <verify>
Run `cd C:/Users/33641/projects/slide-saas/apps/api && npx tsc --noEmit` -- should compile.
Verify `embedding/` directory has 2 files.
Verify `dto/search-kb.dto.ts` exists.
  </verify>
  <done>
- EmbeddingService wraps OpenAI text-embedding-3-small with single + batch methods
- VectorStoreService provides pgvector operations via raw SQL: updateChunkEmbeddings, searchSimilar, deleteDocumentEmbeddings
- SearchKbDto validates query, limit, and threshold parameters
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate embeddings into processor, add search endpoint, update module</name>
  <files>
    apps/api/src/knowledge-base/document-processing.processor.ts
    apps/api/src/knowledge-base/knowledge-base.service.ts
    apps/api/src/knowledge-base/knowledge-base.controller.ts
    apps/api/src/knowledge-base/knowledge-base.module.ts
  </files>
  <action>
**Step 1: Update document-processing.processor.ts** to add embedding after chunk storage.

Read the current processor file (from Plan 02). Make these changes:

Add imports at top:
```typescript
import { EmbeddingService } from './embedding/embedding.service.js';
import { VectorStoreService } from './embedding/vector-store.service.js';
```

Add to constructor parameters (after `urlParser`):
```typescript
private readonly embeddingService: EmbeddingService,
private readonly vectorStore: VectorStoreService,
```

Replace the section that updates status to EMBEDDING (the comment block near the end of the `process` method, roughly step 5). The existing code sets status to EMBEDDING after storing chunks. Modify the logic so that AFTER chunks are stored in the $transaction, we:

1. Keep the status update to EMBEDDING (already there)
2. ADD embedding generation and storage AFTER the EMBEDDING status update
3. ADD final status update to READY

Insert this code AFTER the existing `status: DocumentStatus.EMBEDDING` update:

```typescript
      // 6. Generate embeddings for all chunks
      const storedChunks = await this.prisma.documentChunk.findMany({
        where: { documentId },
        orderBy: { chunkIndex: 'asc' },
        select: { id: true, content: true },
      });

      const texts = storedChunks.map((c) => c.content);
      const embeddings = await this.embeddingService.batchEmbed(texts);

      // 7. Store embeddings via pgvector raw SQL
      const chunkEmbeddings = storedChunks.map((chunk, i) => ({
        chunkId: chunk.id,
        embedding: embeddings[i],
      }));
      await this.vectorStore.updateChunkEmbeddings(documentId, chunkEmbeddings);

      // 8. Update status to READY
      await this.prisma.document.update({
        where: { id: documentId },
        data: {
          status: DocumentStatus.READY,
          processedAt: new Date(),
        },
      });

      this.logger.log(`Document ${documentId}: ${chunks.length} chunks embedded and stored, status=READY`);
```

Also REMOVE the previous status update that set EMBEDDING + chunkCount (step 5 in original), since we now handle both EMBEDDING and READY transitions. The final flow should be:
1. Status -> PARSING
2. Extract text
3. Chunk text
4. Store chunks in DB (transaction)
5. Status -> EMBEDDING, chunkCount updated
6. Generate embeddings
7. Store embeddings in pgvector
8. Status -> READY, processedAt set

**Step 2: Add search method to knowledge-base.service.ts.**

Add imports at top:
```typescript
import { EmbeddingService } from './embedding/embedding.service.js';
import { VectorStoreService } from './embedding/vector-store.service.js';
import type { SearchResult } from './embedding/vector-store.service.js';
```

Add to constructor parameters (after `docQueue`):
```typescript
private readonly embeddingService: EmbeddingService,
private readonly vectorStore: VectorStoreService,
```

Add this method to the class:
```typescript
  async search(
    userId: string,
    query: string,
    limit = 10,
    threshold = 0.3,
  ): Promise<SearchResult[]> {
    // 1. Embed the query
    const queryEmbedding = await this.embeddingService.embed(query);

    // 2. Search via pgvector
    const results = await this.vectorStore.searchSimilar(
      userId,
      queryEmbedding,
      limit,
      threshold,
    );

    return results;
  }
```

**Step 3: Add search endpoint to knowledge-base.controller.ts.**

Add import at top:
```typescript
import { SearchKbDto } from './dto/search-kb.dto.js';
```

Add this endpoint to the controller class (after the deleteDocument method):
```typescript
  @Post('search')
  @HttpCode(HttpStatus.OK)
  async searchKnowledgeBase(
    @CurrentUser() user: RequestUser,
    @Body() dto: SearchKbDto,
  ) {
    return this.kbService.search(
      user.userId,
      dto.query,
      dto.limit,
      dto.threshold,
    );
  }
```

**Step 4: Update knowledge-base.module.ts** to add embedding services.

Add imports at top:
```typescript
import { EmbeddingService } from './embedding/embedding.service.js';
import { VectorStoreService } from './embedding/vector-store.service.js';
```

Add to providers array:
```typescript
EmbeddingService,
VectorStoreService,
```

Add to exports array (needed by Phase 3 for RAG retrieval):
```typescript
exports: [KnowledgeBaseService, S3Service, EmbeddingService, VectorStoreService],
```
  </action>
  <verify>
Run `cd C:/Users/33641/projects/slide-saas/apps/api && npx tsc --noEmit` -- should compile.
Verify processor now imports and uses EmbeddingService and VectorStoreService.
Verify controller has POST /knowledge-base/search endpoint.
Verify module providers include EmbeddingService and VectorStoreService.
Verify module exports include EmbeddingService and VectorStoreService.
  </verify>
  <done>
- Document processing pipeline now runs end-to-end: upload -> parse -> chunk -> embed -> store vectors
- Status transitions: UPLOADED -> PARSING -> EMBEDDING -> READY (or ERROR at any step)
- POST /knowledge-base/search endpoint: accepts query text, embeds it, returns top-k most similar chunks with similarity scores
- Search scoped to user's documents (only READY status, only chunks with embeddings)
- EmbeddingService and VectorStoreService exported from module for Phase 3 reuse
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes
2. `embedding/` directory has 2 files (embedding.service.ts, vector-store.service.ts)
3. Processor imports and uses both embedding services
4. Controller has 7 endpoints: upload, text, url, list, get, delete, search
5. Module exports EmbeddingService and VectorStoreService
6. Vector search uses raw SQL with pgvector `<=>` operator and cosine similarity
7. Embedding batching handles 100 texts per API call
</verification>

<success_criteria>
- Complete document pipeline: upload -> store S3 -> parse -> chunk -> embed (OpenAI) -> store vectors (pgvector)
- Full status lifecycle: UPLOADED -> PARSING -> EMBEDDING -> READY (or ERROR at any step)
- POST /knowledge-base/search returns semantically relevant chunks with similarity scores
- Search is scoped per-user, only returns chunks from READY documents
- Vector operations use raw SQL (not Prisma ORM) with pgvector.toSql()
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/02-knowledge-base/02-03-SUMMARY.md`
</output>
